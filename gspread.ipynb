{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    " import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import gspread\n",
    "import pandas as pd\n",
    "\n",
    "# Please set the Spreadsheet ID.\n",
    "spreadsheetId = \"1rRtLD56MpNPfSThJmzaD0e7yfrUdXMVoDwXU__qYcUM\"\n",
    "# Create an authorized client\n",
    "client = gspread.oauth()\n",
    "spreadsheet = client.open_by_key(spreadsheetId)\n",
    "# Get spreadsheet's worksheets\n",
    "worksheets = spreadsheet.worksheets()\n",
    "# Create a list to hold the values\n",
    "values = []\n",
    "for ws in worksheets:\n",
    "    values.extend(ws.get_all_records())\n",
    "# create df from values\n",
    "df = pd.DataFrame(values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "               id                                      name       group_name  \\\n0      5022926-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n1      5022924-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n2      5022925-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n3      5022923-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n4      5036050-CN               CHANGAN H16EB CRANKSPROCKET              205   \n...           ...                                       ...              ...   \n37905  00.030.250                       Wer macht was? 24+m  Fertigerzeugnis   \n37906  00.031.580                    Was gehört wohin? 24+m  Fertigerzeugnis   \n37907  00.031.754  Was gehört wohin? Auf dem Bauernhof 24+m  Fertigerzeugnis   \n37908  00.031.667                        Wer wohnt wo? 24+m  Fertigerzeugnis   \n37909  00.099.780        WWWjun - Autos u.Laster - Albatros  Fertigerzeugnis   \n\n             manual_match category_raw_name product_type    batch  \\\n0      steel, low-alloyed    steel and iron     material  batch_1   \n1      steel, low-alloyed    steel and iron     material  batch_1   \n2      steel, low-alloyed    steel and iron     material  batch_1   \n3      steel, low-alloyed    steel and iron     material  batch_1   \n4      steel, low-alloyed    steel and iron     material  batch_1   \n...                   ...               ...          ...      ...   \n37905       printed paper    office support     material  batch_1   \n37906       printed paper    office support     material  batch_1   \n37907       printed paper    office support     material  batch_1   \n37908       printed paper    office support     material  batch_1   \n37909       printed paper    office support     material  batch_1   \n\n             source          group_name_2              group_name_3  \n0        Borgwarner                   NaN                       NaN  \n1        Borgwarner                   NaN                       NaN  \n2        Borgwarner                   NaN                       NaN  \n3        Borgwarner                   NaN                       NaN  \n4        Borgwarner                   NaN                       NaN  \n...             ...                   ...                       ...  \n37905  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37906  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37907  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37908  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37909  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n\n[37910 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>group_name</th>\n      <th>manual_match</th>\n      <th>category_raw_name</th>\n      <th>product_type</th>\n      <th>batch</th>\n      <th>source</th>\n      <th>group_name_2</th>\n      <th>group_name_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5022926-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5022924-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5022925-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5022923-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5036050-CN</td>\n      <td>CHANGAN H16EB CRANKSPROCKET</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37905</th>\n      <td>00.030.250</td>\n      <td>Wer macht was? 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37906</th>\n      <td>00.031.580</td>\n      <td>Was gehört wohin? 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37907</th>\n      <td>00.031.754</td>\n      <td>Was gehört wohin? Auf dem Bauernhof 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37908</th>\n      <td>00.031.667</td>\n      <td>Wer wohnt wo? 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37909</th>\n      <td>00.099.780</td>\n      <td>WWWjun - Autos u.Laster - Albatros</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n  </tbody>\n</table>\n<p>37910 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import gspread\n",
    "import pandas as pd\n",
    "\n",
    "def get_spreadsheet_data(spreadsheet_id: str) -> pd.DataFrame:\n",
    "    # Create an authorized client\n",
    "    client = gspread.oauth()\n",
    "    # Open the spreadsheet by ID\n",
    "    spreadsheet = client.open_by_key(spreadsheet_id)\n",
    "    # Get spreadsheet's worksheets\n",
    "    worksheets = spreadsheet.worksheets()\n",
    "    # Create a list to hold the values\n",
    "    values = []\n",
    "    for ws in worksheets:\n",
    "        values.extend(ws.get_all_records())\n",
    "    # create df from values\n",
    "    df = pd.DataFrame(values)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "               id                                      name       group_name  \\\n0      5022926-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n1      5022924-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n2      5022925-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n3      5022923-CN                  SPROCKET-IDLER-BS-IN-24T              205   \n4      5036050-CN               CHANGAN H16EB CRANKSPROCKET              205   \n...           ...                                       ...              ...   \n37905  00.030.250                       Wer macht was? 24+m  Fertigerzeugnis   \n37906  00.031.580                    Was gehört wohin? 24+m  Fertigerzeugnis   \n37907  00.031.754  Was gehört wohin? Auf dem Bauernhof 24+m  Fertigerzeugnis   \n37908  00.031.667                        Wer wohnt wo? 24+m  Fertigerzeugnis   \n37909  00.099.780        WWWjun - Autos u.Laster - Albatros  Fertigerzeugnis   \n\n             manual_match category_raw_name product_type    batch  \\\n0      steel, low-alloyed    steel and iron     material  batch_1   \n1      steel, low-alloyed    steel and iron     material  batch_1   \n2      steel, low-alloyed    steel and iron     material  batch_1   \n3      steel, low-alloyed    steel and iron     material  batch_1   \n4      steel, low-alloyed    steel and iron     material  batch_1   \n...                   ...               ...          ...      ...   \n37905       printed paper    office support     material  batch_1   \n37906       printed paper    office support     material  batch_1   \n37907       printed paper    office support     material  batch_1   \n37908       printed paper    office support     material  batch_1   \n37909       printed paper    office support     material  batch_1   \n\n             source          group_name_2              group_name_3  \n0        Borgwarner                   NaN                       NaN  \n1        Borgwarner                   NaN                       NaN  \n2        Borgwarner                   NaN                       NaN  \n3        Borgwarner                   NaN                       NaN  \n4        Borgwarner                   NaN                       NaN  \n...             ...                   ...                       ...  \n37905  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37906  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37907  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37908  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n37909  Ravensburger  BÜCHER, NUR BUCHVERL  Kinder- und Jugendbücher  \n\n[37910 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>group_name</th>\n      <th>manual_match</th>\n      <th>category_raw_name</th>\n      <th>product_type</th>\n      <th>batch</th>\n      <th>source</th>\n      <th>group_name_2</th>\n      <th>group_name_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5022926-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5022924-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5022925-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5022923-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5036050-CN</td>\n      <td>CHANGAN H16EB CRANKSPROCKET</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37905</th>\n      <td>00.030.250</td>\n      <td>Wer macht was? 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37906</th>\n      <td>00.031.580</td>\n      <td>Was gehört wohin? 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37907</th>\n      <td>00.031.754</td>\n      <td>Was gehört wohin? Auf dem Bauernhof 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37908</th>\n      <td>00.031.667</td>\n      <td>Wer wohnt wo? 24+m</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n    <tr>\n      <th>37909</th>\n      <td>00.099.780</td>\n      <td>WWWjun - Autos u.Laster - Albatros</td>\n      <td>Fertigerzeugnis</td>\n      <td>printed paper</td>\n      <td>office support</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Ravensburger</td>\n      <td>BÜCHER, NUR BUCHVERL</td>\n      <td>Kinder- und Jugendbücher</td>\n    </tr>\n  </tbody>\n</table>\n<p>37910 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spreadsheet_id =\"1rRtLD56MpNPfSThJmzaD0e7yfrUdXMVoDwXU__qYcUM\"\n",
    "get_spreadsheet_data(spreadsheet_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def concat_columns(df: pd.DataFrame, delimiter: str) -> list[str]:\n",
    "    # remove nan\n",
    "    df = df.fillna('')\n",
    "    # Create an empty list to store the concatenated values\n",
    "    concatenated = []\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Concatenate the values of the name, group_name_1, and group_name_2 columns\n",
    "        concat_string = f\"{row['name']}{delimiter}{row['group_name']}{delimiter}{row['group_name_2']}\"\n",
    "        # Remove any extra whitespace\n",
    "        cleaned_string = ' '.join(concat_string.split())\n",
    "        # Add the cleaned string to the list of concatenated values\n",
    "        concatenated.append(cleaned_string)\n",
    "    # Return the list of concatenated strings\n",
    "    return concatenated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                         name group_name  \\\n0       5022926-CN     SPROCKET-IDLER-BS-IN-24T        205   \n1       5022924-CN     SPROCKET-IDLER-BS-IN-24T        205   \n2       5022925-CN     SPROCKET-IDLER-BS-IN-24T        205   \n3       5022923-CN     SPROCKET-IDLER-BS-IN-24T        205   \n4       5036050-CN  CHANGAN H16EB CRANKSPROCKET        205   \n5        ext_id__1           ASM - OUTPUT SHAFT         MR   \n6       2013577__2             PISTON, TWO-STEP         19   \n7       2013577__1             PISTON, TWO-STEP         79   \n8  DWG7470-0263SCR                  Screw-Joint        109   \n9  DWG7470-0345PST                    Piston-OC         96   \n\n         manual_match category_raw_name product_type    batch      source  \\\n0  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n1  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n2  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n3  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n4  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n5  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n6  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n7  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n8  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n9  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n\n  group_name_2 group_name_3  \n0          NaN          NaN  \n1          NaN          NaN  \n2          NaN          NaN  \n3          NaN          NaN  \n4          NaN          NaN  \n5          NaN          NaN  \n6          NaN          NaN  \n7          NaN          NaN  \n8          NaN          NaN  \n9          NaN          NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>group_name</th>\n      <th>manual_match</th>\n      <th>category_raw_name</th>\n      <th>product_type</th>\n      <th>batch</th>\n      <th>source</th>\n      <th>group_name_2</th>\n      <th>group_name_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5022926-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5022924-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5022925-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5022923-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5036050-CN</td>\n      <td>CHANGAN H16EB CRANKSPROCKET</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ext_id__1</td>\n      <td>ASM - OUTPUT SHAFT</td>\n      <td>MR</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2013577__2</td>\n      <td>PISTON, TWO-STEP</td>\n      <td>19</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2013577__1</td>\n      <td>PISTON, TWO-STEP</td>\n      <td>79</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DWG7470-0263SCR</td>\n      <td>Screw-Joint</td>\n      <td>109</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DWG7470-0345PST</td>\n      <td>Piston-OC</td>\n      <td>96</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "['SPROCKET-IDLER-BS-IN-24T 205',\n 'SPROCKET-IDLER-BS-IN-24T 205',\n 'SPROCKET-IDLER-BS-IN-24T 205',\n 'SPROCKET-IDLER-BS-IN-24T 205',\n 'CHANGAN H16EB CRANKSPROCKET 205',\n 'ASM - OUTPUT SHAFT MR',\n 'PISTON, TWO-STEP 19',\n 'PISTON, TWO-STEP 79',\n 'Screw-Joint 109',\n 'Piston-OC 96']"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_columns(df[:10], \" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f\"{delimiter}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "small_df = df[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "                id                         name group_name  \\\n0       5022926-CN     SPROCKET-IDLER-BS-IN-24T        205   \n1       5022924-CN     SPROCKET-IDLER-BS-IN-24T        205   \n2       5022925-CN     SPROCKET-IDLER-BS-IN-24T        205   \n3       5022923-CN     SPROCKET-IDLER-BS-IN-24T        205   \n4       5036050-CN  CHANGAN H16EB CRANKSPROCKET        205   \n5        ext_id__1           ASM - OUTPUT SHAFT         MR   \n6       2013577__2             PISTON, TWO-STEP         19   \n7       2013577__1             PISTON, TWO-STEP         79   \n8  DWG7470-0263SCR                  Screw-Joint        109   \n9  DWG7470-0345PST                    Piston-OC         96   \n\n         manual_match category_raw_name product_type    batch      source  \\\n0  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n1  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n2  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n3  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n4  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n5  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n6  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n7  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n8  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n9  steel, low-alloyed    steel and iron     material  batch_1  Borgwarner   \n\n  group_name_2 group_name_3  \n0          NaN          NaN  \n1          NaN          NaN  \n2          NaN          NaN  \n3          NaN          NaN  \n4          NaN          NaN  \n5          NaN          NaN  \n6          NaN          NaN  \n7          NaN          NaN  \n8          NaN          NaN  \n9          NaN          NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>name</th>\n      <th>group_name</th>\n      <th>manual_match</th>\n      <th>category_raw_name</th>\n      <th>product_type</th>\n      <th>batch</th>\n      <th>source</th>\n      <th>group_name_2</th>\n      <th>group_name_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5022926-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5022924-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5022925-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5022923-CN</td>\n      <td>SPROCKET-IDLER-BS-IN-24T</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5036050-CN</td>\n      <td>CHANGAN H16EB CRANKSPROCKET</td>\n      <td>205</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ext_id__1</td>\n      <td>ASM - OUTPUT SHAFT</td>\n      <td>MR</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2013577__2</td>\n      <td>PISTON, TWO-STEP</td>\n      <td>19</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2013577__1</td>\n      <td>PISTON, TWO-STEP</td>\n      <td>79</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>DWG7470-0263SCR</td>\n      <td>Screw-Joint</td>\n      <td>109</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DWG7470-0345PST</td>\n      <td>Piston-OC</td>\n      <td>96</td>\n      <td>steel, low-alloyed</td>\n      <td>steel and iron</td>\n      <td>material</td>\n      <td>batch_1</td>\n      <td>Borgwarner</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:163\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[0;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:239\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(op, a, b, use_numexpr)\u001B[0m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_numexpr:\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;66;03m# error: \"None\" not callable\u001B[39;00m\n\u001B[0;32m--> 239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:69\u001B[0m, in \u001B[0;36m_evaluate_standard\u001B[0;34m(op, op_str, a, b)\u001B[0m\n\u001B[1;32m     68\u001B[0m     _store_test_result(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mconcat_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmall_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgroup_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgroup_name_2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m, \u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [37]\u001B[0m, in \u001B[0;36mconcat_columns\u001B[0;34m(df, col1, col2, col3, delimiter)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconcat_columns\u001B[39m(df: pd\u001B[38;5;241m.\u001B[39mDataFrame, col1: \u001B[38;5;28mstr\u001B[39m, col2: \u001B[38;5;28mstr\u001B[39m, col3: \u001B[38;5;28mstr\u001B[39m, delimiter: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# create a new column in the DataFrame for the concatenated values\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcatenated\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol1\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m$\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol2\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m df[col3]\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# remove any extra whitespace in the concatenated values\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcatenated\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcatenated\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mstrip()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     66\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     68\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/arraylike.py:100\u001B[0m, in \u001B[0;36mOpsMixin.__add__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__add__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__add__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m--> 100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py:5639\u001B[0m, in \u001B[0;36mSeries._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   5637\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[1;32m   5638\u001B[0m     \u001B[38;5;28mself\u001B[39m, other \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39malign_method_SERIES(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[0;32m-> 5639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/base.py:1295\u001B[0m, in \u001B[0;36mIndexOpsMixin._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   1292\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1295\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(result, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:222\u001B[0m, in \u001B[0;36marithmetic_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     _bool_arith_check(op, left, right)\n\u001B[0;32m--> 222\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43m_na_arithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:170\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[0;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cmp \u001B[38;5;129;01mand\u001B[39;00m (is_object_dtype(left\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(right)):\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001B[39;00m\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;66;03m#  on the non-missing values)\u001B[39;00m\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001B[39;00m\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;66;03m#  incorrectly, see GH#32047\u001B[39;00m\n\u001B[0;32m--> 170\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43m_masked_arith_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    172\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:108\u001B[0m, in \u001B[0;36m_masked_arith_op\u001B[0;34m(x, y, op)\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001B[39;00m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m--> 108\u001B[0m         result[mask] \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(y):\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "concat_columns(small_df, \"name\", \"group_name\", \"group_name_2\", \", \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concat_columns(df: pd.DataFrame, col1: str, col2: str, col3: str) -> pd.DataFrame:\n",
    "    # create a new column in the DataFrame for the concatenated values\n",
    "    df['concatenated'] = df[col1] + '$' + df[col2] + '$' + df[col3]\n",
    "\n",
    "    # remove any extra whitespace in the concatenated values\n",
    "    df['concatenated'] = df['concatenated'].str.strip()\n",
    "\n",
    "    # return the new DataFrame with the concatenated values\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:163\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[0;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:239\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(op, a, b, use_numexpr)\u001B[0m\n\u001B[1;32m    237\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_numexpr:\n\u001B[1;32m    238\u001B[0m         \u001B[38;5;66;03m# error: \"None\" not callable\u001B[39;00m\n\u001B[0;32m--> 239\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:69\u001B[0m, in \u001B[0;36m_evaluate_standard\u001B[0;34m(op, op_str, a, b)\u001B[0m\n\u001B[1;32m     68\u001B[0m     _store_test_result(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [43]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mconcat_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmall_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgroup_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgroup_name_2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [42]\u001B[0m, in \u001B[0;36mconcat_columns\u001B[0;34m(df, col1, col2, col3)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconcat_columns\u001B[39m(df: pd\u001B[38;5;241m.\u001B[39mDataFrame, col1: \u001B[38;5;28mstr\u001B[39m, col2: \u001B[38;5;28mstr\u001B[39m, col3: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# create a new column in the DataFrame for the concatenated values\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcatenated\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol1\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m$\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol2\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m$\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m df[col3]\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# remove any extra whitespace in the concatenated values\u001B[39;00m\n\u001B[1;32m      8\u001B[0m     df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcatenated\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconcatenated\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mstrip()\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/common.py:70\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     66\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m     68\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[0;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/arraylike.py:100\u001B[0m, in \u001B[0;36mOpsMixin.__add__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__add__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__add__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[0;32m--> 100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py:5639\u001B[0m, in \u001B[0;36mSeries._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   5637\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_arith_method\u001B[39m(\u001B[38;5;28mself\u001B[39m, other, op):\n\u001B[1;32m   5638\u001B[0m     \u001B[38;5;28mself\u001B[39m, other \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39malign_method_SERIES(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[0;32m-> 5639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbase\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIndexOpsMixin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_arith_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/base.py:1295\u001B[0m, in \u001B[0;36mIndexOpsMixin._arith_method\u001B[0;34m(self, other, op)\u001B[0m\n\u001B[1;32m   1292\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m np\u001B[38;5;241m.\u001B[39merrstate(\u001B[38;5;28mall\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1295\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_result(result, name\u001B[38;5;241m=\u001B[39mres_name)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:222\u001B[0m, in \u001B[0;36marithmetic_op\u001B[0;34m(left, right, op)\u001B[0m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     _bool_arith_check(op, left, right)\n\u001B[0;32m--> 222\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[43m_na_arithmetic_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m res_values\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:170\u001B[0m, in \u001B[0;36m_na_arithmetic_op\u001B[0;34m(left, right, op, is_cmp)\u001B[0m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cmp \u001B[38;5;129;01mand\u001B[39;00m (is_object_dtype(left\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(right)):\n\u001B[1;32m    166\u001B[0m         \u001B[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001B[39;00m\n\u001B[1;32m    167\u001B[0m         \u001B[38;5;66;03m#  on the non-missing values)\u001B[39;00m\n\u001B[1;32m    168\u001B[0m         \u001B[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001B[39;00m\n\u001B[1;32m    169\u001B[0m         \u001B[38;5;66;03m#  incorrectly, see GH#32047\u001B[39;00m\n\u001B[0;32m--> 170\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43m_masked_arith_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43mleft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mright\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    172\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py:108\u001B[0m, in \u001B[0;36m_masked_arith_op\u001B[0;34m(x, y, op)\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001B[39;00m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m--> 108\u001B[0m         result[mask] \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43myrav\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(y):\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "concat_columns(small_df, \"name\", \"group_name\", \"group_name_2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concat_columns_combinations(df: pd.DataFrame) -> list[str]:\n",
    "    # Create an empty list to store the concatenated values\n",
    "    concatenated = []\n",
    "    df = df.fillna('')\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Concatenate the values of the name, group_name_1, and group_name_2 columns\n",
    "        concat_string_1 = f\"{row['name']}${row['group_name']}${row['group_name_2']}\"\n",
    "        concat_string_2 = f\"{row['name']}${row['group_name_2']}${row['group_name']}\"\n",
    "        concat_string_3 = f\"{row['group_name']}${row['name']}${row['group_name_2']}\"\n",
    "        concat_string_4 = f\"{row['group_name']}${row['group_name_2']}${row['name']}\"\n",
    "        concat_string_5 = f\"{row['group_name_2']}${row['name']}${row['group_name']}\"\n",
    "        concat_string_6 = f\"{row['group_name_2']}${row['group_name']}${row['name']}\"\n",
    "\n",
    "        # Remove any extra whitespace\n",
    "        cleaned_string_1 = ' '.join(concat_string_1.split())\n",
    "        cleaned_string_2 = ' '.join(concat_string_2.split())\n",
    "        cleaned_string_3 = ' '.join(concat_string_3.split())\n",
    "        cleaned_string_4 = ' '.join(concat_string_4.split())\n",
    "        cleaned_string_5 = ' '.join(concat_string_5.split())\n",
    "        cleaned_string_6 = ' '.join(concat_string_6.split())\n",
    "\n",
    "        # Add the cleaned strings to the list of concatenated values\n",
    "        concatenated.extend([cleaned_string_1, cleaned_string_2, cleaned_string_3, cleaned_string_4, cleaned_string_5, cleaned_string_6])\n",
    "\n",
    "    # Return the list of concatenated strings\n",
    "    return concatenated\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "['SPROCKET-IDLER-BS-IN-24T$205$',\n 'SPROCKET-IDLER-BS-IN-24T$$205',\n '205$SPROCKET-IDLER-BS-IN-24T$',\n '205$$SPROCKET-IDLER-BS-IN-24T',\n '$SPROCKET-IDLER-BS-IN-24T$205',\n '$205$SPROCKET-IDLER-BS-IN-24T',\n 'SPROCKET-IDLER-BS-IN-24T$205$',\n 'SPROCKET-IDLER-BS-IN-24T$$205',\n '205$SPROCKET-IDLER-BS-IN-24T$',\n '205$$SPROCKET-IDLER-BS-IN-24T',\n '$SPROCKET-IDLER-BS-IN-24T$205',\n '$205$SPROCKET-IDLER-BS-IN-24T',\n 'SPROCKET-IDLER-BS-IN-24T$205$',\n 'SPROCKET-IDLER-BS-IN-24T$$205',\n '205$SPROCKET-IDLER-BS-IN-24T$',\n '205$$SPROCKET-IDLER-BS-IN-24T',\n '$SPROCKET-IDLER-BS-IN-24T$205',\n '$205$SPROCKET-IDLER-BS-IN-24T']"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_columns_combinations(df[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concat_columns(df: pd.DataFrame, delimiter: str = '$') -> list[tuple[str, int]]:\n",
    "    # Create an empty list to store the concatenated values\n",
    "    concatenated = []\n",
    "\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Generate all possible combinations of group_name_1 and group_name_2\n",
    "        groups = [(row['group_name'], row['group_name_2']), (row['name'])]\n",
    "\n",
    "        # Iterate over the possible combinations\n",
    "        for group in groups:\n",
    "            # Concatenate the values of the name, group_name_1, and group_name_2 columns with the specified delimiter\n",
    "            concat_string = f\"{row['name']}{delimiter}{group[0]}{delimiter}{group[1]}\"\n",
    "            # Remove any extra whitespace\n",
    "            cleaned_string = ' '.join(concat_string.split())\n",
    "            # Add the cleaned string and index to the list of concatenated values\n",
    "            concatenated.append((cleaned_string, index))\n",
    "\n",
    "    # Return the list of concatenated strings\n",
    "    return concatenated\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concat_columns_combinations(df: pd.DataFrame, delimiter: str = '$') -> list[tuple]:\n",
    "    # Create an empty list to store the concatenated values\n",
    "    concatenated = []\n",
    "    df = df.fillna('')\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Concatenate the values of the name, group_name_1, and group_name_2 columns\n",
    "        concat_string_1 = f\"{row['name']}{delimiter}{row['group_name']}{delimiter}{row['group_name_2']}\"\n",
    "        concat_string_2 = f\"{row['name']}{delimiter}{row['group_name_2']}{delimiter}{row['group_name']}\"\n",
    "        concat_string_3 = f\"{row['group_name']}{delimiter}{row['name']}{delimiter}{row['group_name_2']}\"\n",
    "        concat_string_4 = f\"{row['group_name']}{delimiter}{row['group_name_2']}{delimiter}{row['name']}\"\n",
    "        concat_string_5 = f\"{row['group_name_2']}{delimiter}{row['name']}{delimiter}{row['group_name']}\"\n",
    "        concat_string_6 = f\"{row['group_name_2']}{delimiter}{row['group_name']}{delimiter}{row['name']}\"\n",
    "\n",
    "        # Remove any extra whitespace\n",
    "        cleaned_string_1 = ' '.join(concat_string_1.split())\n",
    "        cleaned_string_2 = ' '.join(concat_string_2.split())\n",
    "        cleaned_string_3 = ' '.join(concat_string_3.split())\n",
    "        cleaned_string_4 = ' '.join(concat_string_4.split())\n",
    "        cleaned_string_5 = ' '.join(concat_string_5.split())\n",
    "        cleaned_string_6 = ' '.join(concat_string_6.split())\n",
    "\n",
    "        # Add the cleaned strings to the list of concatenated values as tuples with index\n",
    "        concatenated.extend([(index+1, cleaned_string_1), (index+1, cleaned_string_2), (index+1, cleaned_string_3), (index+1, cleaned_string_4), (index+1, cleaned_string_5), (index+1, cleaned_string_6)])\n",
    "\n",
    "    # Return the list of concatenated strings as tuples\n",
    "    return concatenated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "[(1, 'SPROCKET-IDLER-BS-IN-24T$205$'),\n (1, 'SPROCKET-IDLER-BS-IN-24T$$205'),\n (1, '205$SPROCKET-IDLER-BS-IN-24T$'),\n (1, '205$$SPROCKET-IDLER-BS-IN-24T'),\n (1, '$SPROCKET-IDLER-BS-IN-24T$205'),\n (1, '$205$SPROCKET-IDLER-BS-IN-24T'),\n (2, 'SPROCKET-IDLER-BS-IN-24T$205$'),\n (2, 'SPROCKET-IDLER-BS-IN-24T$$205'),\n (2, '205$SPROCKET-IDLER-BS-IN-24T$'),\n (2, '205$$SPROCKET-IDLER-BS-IN-24T'),\n (2, '$SPROCKET-IDLER-BS-IN-24T$205'),\n (2, '$205$SPROCKET-IDLER-BS-IN-24T'),\n (3, 'SPROCKET-IDLER-BS-IN-24T$205$'),\n (3, 'SPROCKET-IDLER-BS-IN-24T$$205'),\n (3, '205$SPROCKET-IDLER-BS-IN-24T$'),\n (3, '205$$SPROCKET-IDLER-BS-IN-24T'),\n (3, '$SPROCKET-IDLER-BS-IN-24T$205'),\n (3, '$205$SPROCKET-IDLER-BS-IN-24T')]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_columns_combinations(df[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "sentences = ['SPROCKET-IDLER-BS-IN-24T$205$',\n",
    " 'SPROCKET-IDLER-BS-IN-24T$$205',\n",
    " ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def get_positive_pairs(sentences: List[str]) -> List[List[str]]:\n",
    "    # Create a list to store the positive pairs\n",
    "    positive_pairs = []\n",
    "\n",
    "    # Loop through each sentence in the list\n",
    "    for i, s1 in enumerate(sentences):\n",
    "        # Loop through the remaining sentences in the list\n",
    "        for s2 in sentences[i+1:]:\n",
    "            # Create a set of the two sentences\n",
    "            s = set([s1, s2])\n",
    "\n",
    "            # Add the set to the list of positive pairs\n",
    "            positive_pairs.append(list(s))\n",
    "\n",
    "    return positive_pairs\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "[['SPROCKET-IDLER-BS-IN-24T$$205', 'SPROCKET-IDLER-BS-IN-24T$205$']]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_positive_pairs(sentences )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def concat_columns_combinations(df: pd.DataFrame, delimiter: str = '$') -> list[tuple]:\n",
    "    # Create an empty list to store the concatenated values\n",
    "    concatenated = []\n",
    "    df = df.fillna('')\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Concatenate the values of the name, group_name_1, and group_name_2 columns\n",
    "        concat_string_1 = f\"{row['name']}{delimiter}{row['group_name']}{delimiter}{row['group_name_2']}\"\n",
    "        concat_string_2 = f\"{row['name']}{delimiter}{row['group_name_2']}{delimiter}{row['group_name']}\"\n",
    "        concat_string_3 = f\"{row['group_name']}{delimiter}{row['name']}{delimiter}{row['group_name_2']}\"\n",
    "        concat_string_4 = f\"{row['group_name']}{delimiter}{row['group_name_2']}{delimiter}{row['name']}\"\n",
    "        concat_string_5 = f\"{row['group_name_2']}{delimiter}{row['name']}{delimiter}{row['group_name']}\"\n",
    "        concat_string_6 = f\"{row['group_name_2']}{delimiter}{row['group_name']}{delimiter}{row['name']}\"\n",
    "\n",
    "        # Remove any extra whitespace\n",
    "        cleaned_string_1 = ' '.join(concat_string_1.split())\n",
    "        cleaned_string_2 = ' '.join(concat_string_2.split())\n",
    "        cleaned_string_3 = ' '.join(concat_string_3.split())\n",
    "        cleaned_string_4 = ' '.join(concat_string_4.split())\n",
    "        cleaned_string_5 = ' '.join(concat_string_5.split())\n",
    "        cleaned_string_6 = ' '.join(concat_string_6.split())\n",
    "\n",
    "        # Add the cleaned strings to the list of concatenated values as tuples with index\n",
    "        concatenated.extend(\n",
    "            [(index + 1, cleaned_string_1), (index + 1, cleaned_string_2), (index + 1, cleaned_string_3),\n",
    "             (index + 1, cleaned_string_4), (index + 1, cleaned_string_5), (index + 1, cleaned_string_6)])\n",
    "\n",
    "\n",
    "\n",
    "    return concatenated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "test =concat_columns_combinations(df[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPROCKET-IDLER-BS-IN-24T$205$\n",
      "SPROCKET-IDLER-BS-IN-24T$$205\n",
      "205$SPROCKET-IDLER-BS-IN-24T$\n",
      "205$$SPROCKET-IDLER-BS-IN-24T\n",
      "$SPROCKET-IDLER-BS-IN-24T$205\n",
      "$205$SPROCKET-IDLER-BS-IN-24T\n",
      "SPROCKET-IDLER-BS-IN-24T$205$\n",
      "SPROCKET-IDLER-BS-IN-24T$$205\n",
      "205$SPROCKET-IDLER-BS-IN-24T$\n",
      "205$$SPROCKET-IDLER-BS-IN-24T\n",
      "$SPROCKET-IDLER-BS-IN-24T$205\n",
      "$205$SPROCKET-IDLER-BS-IN-24T\n",
      "SPROCKET-IDLER-BS-IN-24T$205$\n",
      "SPROCKET-IDLER-BS-IN-24T$$205\n",
      "205$SPROCKET-IDLER-BS-IN-24T$\n",
      "205$$SPROCKET-IDLER-BS-IN-24T\n",
      "$SPROCKET-IDLER-BS-IN-24T$205\n",
      "$205$SPROCKET-IDLER-BS-IN-24T\n"
     ]
    }
   ],
   "source": [
    "for t in test:\n",
    "    print(t[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords 1:  ['Bags', 'corn', 'RFID']\n",
      "Keywords 2:  ['CK75M1GKZ+K610']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "text_1 = \"Bags corn, Bag MA OKS 42x75x12 50TK AM RFID 18/19\"\n",
    "text_2 = \"BD S130337-22-1X68GK-CK75M1GKZ+K610\"\n",
    "def extract_keywords(text: str) -> list[str]:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    keywords = [token.text for token in doc if token.pos_ in ['NOUN', 'VERB', 'ADJ']]\n",
    "    return keywords\n",
    "\n",
    "keywords_1 = extract_keywords(text_1)\n",
    "print(\"Keywords 1: \", keywords_1)\n",
    "\n",
    "keywords_2 = extract_keywords(text_2)\n",
    "print(\"Keywords 2: \", keywords_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mCollecting en-core-web-sm==3.4.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m8.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/site-packages (from en-core-web-sm==3.4.1) (3.4.1)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (65.3.0)\r\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.63.1)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.3)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\r\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.27.1)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.22.1)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.6)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.9.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.0)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.8)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.4)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.7)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.7)\r\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.0.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2021.10.8)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.26.8)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.10)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.8)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\r\n",
      "Installing collected packages: en-core-web-sm\r\n",
      "\u001B[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001B[0m\u001B[33m\r\n",
      "\u001B[0mSuccessfully installed en-core-web-sm-3.4.1\r\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\r\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E002] Can't find factory for 'The_fres' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, future_entity_ruler, span_ruler, textcat_multilabel, en.lemmatizer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m     nlp\u001B[38;5;241m.\u001B[39mvocab\u001B[38;5;241m.\u001B[39mstrings\u001B[38;5;241m.\u001B[39madd(ent)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# create a new blank entity recognizer and add it to the pipeline\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m ner \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_pipe\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mThe_fres\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m nlp\u001B[38;5;241m.\u001B[39madd_pipe(ner)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# add the new entities to the entity recognizer\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/spacy/language.py:655\u001B[0m, in \u001B[0;36mLanguage.create_pipe\u001B[0;34m(self, factory_name, name, config, raw_config, validate)\u001B[0m\n\u001B[1;32m    647\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhas_factory(factory_name):\n\u001B[1;32m    648\u001B[0m     err \u001B[38;5;241m=\u001B[39m Errors\u001B[38;5;241m.\u001B[39mE002\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    649\u001B[0m         name\u001B[38;5;241m=\u001B[39mfactory_name,\n\u001B[1;32m    650\u001B[0m         opts\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfactory_names),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    653\u001B[0m         lang_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlang,\n\u001B[1;32m    654\u001B[0m     )\n\u001B[0;32m--> 655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err)\n\u001B[1;32m    656\u001B[0m pipe_meta \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_factory_meta(factory_name)\n\u001B[1;32m    657\u001B[0m \u001B[38;5;66;03m# This is unideal, but the alternative would mean you always need to\u001B[39;00m\n\u001B[1;32m    658\u001B[0m \u001B[38;5;66;03m# specify the full config settings, which is not really viable.\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: [E002] Can't find factory for 'The_fres' for language English (en). This usually happens when spaCy calls `nlp.create_pipe` with a custom component name that's not registered on the current language class. If you're using a Transformer, make sure to install 'spacy-transformers'. If you're using a custom component, make sure you've added the decorator `@Language.component` (for function components) or `@Language.factory` (for class components).\n\nAvailable factories: attribute_ruler, tok2vec, merge_noun_chunks, merge_entities, merge_subtokens, token_splitter, doc_cleaner, parser, beam_parser, lemmatizer, trainable_lemmatizer, entity_linker, ner, beam_ner, entity_ruler, tagger, morphologizer, senter, sentencizer, textcat, spancat, future_entity_ruler, span_ruler, textcat_multilabel, en.lemmatizer"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add new entities to the existing model\n",
    "new_ents = [\"KEYWORD1\", \"KEYWORD2\"]\n",
    "for ent in new_ents:\n",
    "    nlp.vocab.strings.add(ent)\n",
    "\n",
    "# create a new blank entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe(\"The_fres\")\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# add the new entities to the entity recognizer\n",
    "for ent in new_ents:\n",
    "    ner.add_label(ent)\n",
    "\n",
    "# define your custom dataset\n",
    "train_data = [\n",
    "    (\"text with KEYWORD1 and KEYWORD2\", {\"entities\": [(15, 23, \"KEYWORD1\"), (28, 36, \"KEYWORD2\")]}),\n",
    "    (\"text with KEYWORD1\", {\"entities\": [(15, 23, \"KEYWORD1\")]}),\n",
    "    (\"text without any entities\", {\"entities\": []})\n",
    "]\n",
    "\n",
    "# train the new model\n",
    "nlp.begin_training()\n",
    "for epoch in range(10):\n",
    "    for text, annotations in train_data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        nlp.update([example], losses={})\n",
    "\n",
    "# test the trained model\n",
    "doc = nlp(\"text with KEYWORD1 and KEYWORD2\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E955] Can't find table(s) lexeme_norm for language 'en' in spacy-lookups-data. Make sure you have the package installed or provide your own lookup tables if no default lookups are available for your language.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m     19\u001B[0m nlp\u001B[38;5;241m.\u001B[39mdisable_pipes(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mner\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43mnlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin_training\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m):\n\u001B[1;32m     23\u001B[0m     random\u001B[38;5;241m.\u001B[39mshuffle(TRAIN_DATA)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/spacy/language.py:1258\u001B[0m, in \u001B[0;36mLanguage.begin_training\u001B[0;34m(self, get_examples, sgd)\u001B[0m\n\u001B[1;32m   1251\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbegin_training\u001B[39m(\n\u001B[1;32m   1252\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1253\u001B[0m     get_examples: Optional[Callable[[], Iterable[Example]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1254\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   1255\u001B[0m     sgd: Optional[Optimizer] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1256\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optimizer:\n\u001B[1;32m   1257\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(Warnings\u001B[38;5;241m.\u001B[39mW089, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[0;32m-> 1258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mget_examples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msgd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msgd\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/spacy/language.py:1290\u001B[0m, in \u001B[0;36mLanguage.initialize\u001B[0;34m(self, get_examples, sgd)\u001B[0m\n\u001B[1;32m   1288\u001B[0m config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39minterpolate()\n\u001B[1;32m   1289\u001B[0m \u001B[38;5;66;03m# These are the settings provided in the [initialize] block in the config\u001B[39;00m\n\u001B[0;32m-> 1290\u001B[0m I \u001B[38;5;241m=\u001B[39m \u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minitialize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mConfigSchemaInit\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1291\u001B[0m before_init \u001B[38;5;241m=\u001B[39m I[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbefore_init\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m before_init \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/thinc/config.py:747\u001B[0m, in \u001B[0;36mregistry.resolve\u001B[0;34m(cls, config, schema, overrides, validate)\u001B[0m\n\u001B[1;32m    738\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    739\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresolve\u001B[39m(\n\u001B[1;32m    740\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    745\u001B[0m     validate: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    746\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m--> 747\u001B[0m     resolved, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    748\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    749\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resolved\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/thinc/config.py:796\u001B[0m, in \u001B[0;36mregistry._make\u001B[0;34m(cls, config, schema, overrides, resolve, validate)\u001B[0m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interpolated:\n\u001B[1;32m    795\u001B[0m     config \u001B[38;5;241m=\u001B[39m Config(orig_config)\u001B[38;5;241m.\u001B[39minterpolate()\n\u001B[0;32m--> 796\u001B[0m filled, _, resolved \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    799\u001B[0m filled \u001B[38;5;241m=\u001B[39m Config(filled, section_order\u001B[38;5;241m=\u001B[39msection_order)\n\u001B[1;32m    800\u001B[0m \u001B[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/thinc/config.py:868\u001B[0m, in \u001B[0;36mregistry._fill\u001B[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[0m\n\u001B[1;32m    865\u001B[0m     getter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget(reg_name, func_name)\n\u001B[1;32m    866\u001B[0m     \u001B[38;5;66;03m# We don't want to try/except this and raise our own error\u001B[39;00m\n\u001B[1;32m    867\u001B[0m     \u001B[38;5;66;03m# here, because we want the traceback if the function fails.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m     getter_result \u001B[38;5;241m=\u001B[39m \u001B[43mgetter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# We're not resolving and calling the function, so replace\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;66;03m# the getter_result with a Promise class\u001B[39;00m\n\u001B[1;32m    872\u001B[0m     getter_result \u001B[38;5;241m=\u001B[39m Promise(\n\u001B[1;32m    873\u001B[0m         registry\u001B[38;5;241m=\u001B[39mreg_name, name\u001B[38;5;241m=\u001B[39mfunc_name, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs\n\u001B[1;32m    874\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/spacy/language.py:108\u001B[0m, in \u001B[0;36mload_lookups_data\u001B[0;34m(lang, tables)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;129m@registry\u001B[39m\u001B[38;5;241m.\u001B[39mmisc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspacy.LookupsDataLoader.v1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_lookups_data\u001B[39m(lang, tables):\n\u001B[1;32m    107\u001B[0m     util\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading lookups from spacy-lookups-data: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtables\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 108\u001B[0m     lookups \u001B[38;5;241m=\u001B[39m \u001B[43mload_lookups\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlang\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlang\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtables\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtables\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lookups\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/spacy/lookups.py:30\u001B[0m, in \u001B[0;36mload_lookups\u001B[0;34m(lang, tables, strict)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lang \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m registry\u001B[38;5;241m.\u001B[39mlookups:\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m strict \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(tables) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 30\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE955\u001B[38;5;241m.\u001B[39mformat(table\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(tables), lang\u001B[38;5;241m=\u001B[39mlang))\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lookups\n\u001B[1;32m     32\u001B[0m data \u001B[38;5;241m=\u001B[39m registry\u001B[38;5;241m.\u001B[39mlookups\u001B[38;5;241m.\u001B[39mget(lang)\n",
      "\u001B[0;31mValueError\u001B[0m: [E955] Can't find table(s) lexeme_norm for language 'en' in spacy-lookups-data. Make sure you have the package installed or provide your own lookup tables if no default lookups are available for your language."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "# Load the model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define the new entity label and add it to the entity recognizer\n",
    "LABEL = \"RFID\"\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(LABEL)\n",
    "\n",
    "# Define the training data\n",
    "TRAIN_DATA = [\n",
    "    (\"text with KEYWORD1 and KEYWORD2\", {\"entities\": [(15, 23, \"KEYWORD1\"), (28, 36, \"KEYWORD2\")]}),\n",
    "    (\"text with KEYWORD1\", {\"entities\": [(15, 23, \"KEYWORD1\")]}),\n",
    "    (\"text without any entities\", {\"entities\": []})\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "nlp.disable_pipes(\"ner\")\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "for i in range(20):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        nlp.update([text], [annotations], sgd=optimizer)\n",
    "\n",
    "nlp.enable_pipes(\"ner\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_1 = \"Beizmittel MA Poncho FS 600, Treatment corn, Treatment corn\"\n",
    "exp_2 = \"Beizmittel MA Poncho FS 600, Treatment corn, treatment corn\"\n",
    "\n",
    "# Split the string into a list of words\n",
    "words_1 = exp_1.split()\n",
    "words_2 = exp_2.split()\n",
    "\n",
    "# Create a set to eliminate duplicates\n",
    "unique_words_1 = set(words_1)\n",
    "unique_words_2 = set(words_2)\n",
    "\n",
    "# Join the unique words back into a string\n",
    "new_exp_1 = ' '.join(unique_words_1)\n",
    "new_exp_2 = ' '.join(unique_words_2)\n",
    "\n",
    "# Print the new expressions without the repeated words\n",
    "print(new_exp_1)\n",
    "print(new_exp_2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corn, corn MA FS Beizmittel Treatment 600, Poncho\n",
      "corn, corn MA FS treatment Beizmittel Treatment 600, Poncho\n"
     ]
    }
   ],
   "source": [
    "exp_1 = \"Beizmittel MA Poncho FS 600, Treatment corn, Treatment corn corn corn\"\n",
    "exp_2 = \"Beizmittel MA Poncho FS 600, Treatment corn, treatment corn\"\n",
    "\n",
    "# Split the string into a list of words\n",
    "words_1 = exp_1.split()\n",
    "words_2 = exp_2.split()\n",
    "\n",
    "# Create a set to eliminate duplicates\n",
    "unique_words_1 = set(words_1)\n",
    "unique_words_2 = set(words_2)\n",
    "\n",
    "# Join the unique words back into a string\n",
    "new_exp_1 = ' '.join(unique_words_1)\n",
    "new_exp_2 = ' '.join(unique_words_2)\n",
    "\n",
    "# Print the new expressions without the repeated words\n",
    "print(new_exp_1)\n",
    "print(new_exp_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'600,', 'Beizmittel', 'FS', 'MA', 'Poncho', 'Treatment', 'corn', 'corn,'}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'600,',\n 'Beizmittel',\n 'FS',\n 'MA',\n 'Poncho',\n 'Treatment',\n 'corn',\n 'corn,',\n 'treatment'}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def eliminate_repeated_words(input_text):\n",
    "    if isinstance(input_text, str):\n",
    "        input_text = [input_text]\n",
    "    return [(\" \".join(sorted(set(text.split()), key=text.split().index))) for text in input_text]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['Beizmittel MA Poncho FS 600, Treatment corn, corn']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def eliminate_repeated_words(text):\n",
    "    if isinstance(text, str):\n",
    "        text = [text]\n",
    "    result = []\n",
    "    for t in text:\n",
    "        words = t.lower().split()\n",
    "        words = sorted(set(words), key=words.index)\n",
    "        result.append(\" \".join(words))\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "['beizmittel ma poncho fs 600, treatment corn, corn']"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminate_repeated_words(exp_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import re\n",
    "def eliminate_repeated_words(text):\n",
    "    if isinstance(text, str):\n",
    "        # convert the string to lowercase and split by delimiter\n",
    "        words = [word.lower() for word in re.split(r'[^\\w]+', text)]\n",
    "    elif isinstance(text, list):\n",
    "        # convert each string in the list to lowercase and split by delimiter\n",
    "        words = [word.lower() for text_str in text for word in re.split(r'[^\\w]+', text_str)]\n",
    "    else:\n",
    "        # raise an error if input is not a string or list of strings\n",
    "        raise ValueError(\"Input must be a string or a list of strings.\")\n",
    "\n",
    "    # eliminate repeated words while preserving order\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "\n",
    "    # join the unique words with delimiter\n",
    "    output_text = ' '.join(unique_words)\n",
    "\n",
    "    return output_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "'petrol 15 etbe additive by volume with ethanol from biomass'"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminate_repeated_words(\"petrol, 15% ETBE additive by volume, with ethanol from biomass\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:  ['Bags', 'corn', ',', 'Bag', 'MA', 'OKS', '42x75x12', '50TK', 'RFID', '18/19']\n",
      "Context 2:  ['petrol', ',', '15', '%', 'ETBE', 'additive', 'volume', ',', 'ethanol', 'biomass']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def derive_context(text: str) -> list[str]:\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    context = [token.text for token in doc if not token.is_stop]\n",
    "    return context\n",
    "\n",
    "text_1 = \"Bags corn, Bag MA OKS 42x75x12 50TK AM RFID 18/19\"\n",
    "text_2 = \"petrol, 15% ETBE additive by volume, with ethanol from biomass\"\n",
    "\n",
    "context_1 = derive_context(text_1)\n",
    "print(\"Context 1: \", context_1)\n",
    "\n",
    "context_2 = derive_context(text_2)\n",
    "print(\"Context 2: \", context_2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "\n",
    "def create_negatives(pos_data: List[str], model_name_or_path: str) -> List[str]:\n",
    "    # Load SentenceTransformer model\n",
    "    model = SentenceTransformer(model_name_or_path)\n",
    "\n",
    "    # Create a list to store the negative examples\n",
    "    neg_data = []\n",
    "\n",
    "    # Iterate over the positive examples\n",
    "    for pos in pos_data:\n",
    "        # Get the embeddings for the positive example\n",
    "        pos_emb = model.encode([pos], convert_to_tensor=True)\n",
    "\n",
    "        # Get the cosine similarity between the positive example and all other examples\n",
    "        cos_sim = util.pytorch_cos_sim(pos_emb, model.encode(pos_data, convert_to_tensor=True)).flatten().numpy()\n",
    "\n",
    "        # Get the indices of examples that belong to the same class as the positive example\n",
    "        same_class_indices = np.where(np.array(pos_data) == pos)[0]\n",
    "\n",
    "        # Loop until a negative example is found\n",
    "        found_neg = False\n",
    "        while not found_neg:\n",
    "            # Get a random example that is not from the same class as the positive example\n",
    "            neg_index = random.choice(range(len(pos_data)))\n",
    "            if neg_index not in same_class_indices:\n",
    "                # Get the embedding for the negative example\n",
    "                neg_emb = model.encode([pos_data[neg_index]], convert_to_tensor=True)\n",
    "\n",
    "                # Get the cosine similarity between the positive and negative examples\n",
    "                neg_cos_sim = util.pytorch_cos_sim(pos_emb, neg_emb).flatten().item()\n",
    "\n",
    "                # If the cosine similarity is below a threshold, add the negative example to the list and exit loop\n",
    "                if neg_cos_sim < 0.2:\n",
    "                    neg_data.append(pos_data[neg_index])\n",
    "                    found_neg = True\n",
    "\n",
    "    return neg_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example usage\n",
    "pos_data = ['I love pizza', 'I enjoy reading books', 'I am good at playing tennis']\n",
    "neg_data = create_negatives(pos_data, 'paraphrase-MiniLM-L6-v2')\n",
    "print(neg_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}